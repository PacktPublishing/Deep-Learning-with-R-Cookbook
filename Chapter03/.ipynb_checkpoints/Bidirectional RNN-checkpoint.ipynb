{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "imdb <- dataset_imdb(num_words = 2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x <- imdb$train$x\n",
    "train_y <- imdb$train$y\n",
    "test_x <- imdb$test$x\n",
    "test_y <- imdb$test$y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000 train sequences\n",
      "25000 test sequences"
     ]
    }
   ],
   "source": [
    "# number of samples in train and test set\n",
    "cat(length(train_x), 'train sequences\\n')\n",
    "cat(length(test_x), 'test sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# str(train_x)\n",
    "\n",
    "# train_x[[1]]\n",
    "# cat(\"Number of words in the first review is\",length(train_x[[1]]))\n",
    "\n",
    "# word_index = dataset_reuters_word_index()\n",
    "\n",
    "# head(word_index)\n",
    "\n",
    "# length((word_index))\n",
    "\n",
    "# reverse_word_index <- names(word_index)\n",
    "# names(reverse_word_index) <- word_index\n",
    "# head(reverse_word_index)\n",
    "\n",
    "# decoded_news <- sapply(train_x[[100]], function(index) {\n",
    "#   word <- if (index >= 3) reverse_word_index[[as.character(index -3)]]\n",
    "#   if (!is.null(word)) word else \"?\"\n",
    "# })\n",
    "\n",
    "# cat(decoded_news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: 25000 80 \n",
      "x_test shape: 25000 80 \n"
     ]
    }
   ],
   "source": [
    "train_x <- pad_sequences(train_x, maxlen = 80)\n",
    "test_x <- pad_sequences(test_x, maxlen = 80)\n",
    "\n",
    "cat('x_train shape:', dim(train_x), '\\n')\n",
    "cat('x_test shape:', dim(test_x), '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step1:**\n",
    "In this section we will be working with IMDB data set. Data preperation steps are same as the previous section, _Classifying sentiments with recurrent neural network_.Let us start by instantiating our sequential model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model <- keras_model_sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2 :** Let us now add layers to our model and print out its summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Layer (type)                        Output Shape                    Param #     \n",
      "================================================================================\n",
      "embedding (Embedding)               (None, None, 128)               256000      \n",
      "________________________________________________________________________________\n",
      "bidirectional (Bidirectional)       (None, 64)                      10304       \n",
      "________________________________________________________________________________\n",
      "dense (Dense)                       (None, 1)                       65          \n",
      "================================================================================\n",
      "Total params: 266,369\n",
      "Trainable params: 266,369\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model %>%\n",
    "  layer_embedding(input_dim = 2000, output_dim = 128) %>% \n",
    "  bidirectional(layer_simple_rnn(units = 32),merge_mode = \"concat\") %>% \n",
    "  layer_dense(units = 1, activation = 'sigmoid')\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:** Lets compile and train our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile model\n",
    "model %>% compile(\n",
    "  loss = \"binary_crossentropy\",\n",
    "  optimizer = \"adam\",\n",
    "  metrics = c(\"accuracy\")\n",
    ")\n",
    "\n",
    "# train model\n",
    "model %>% fit(\n",
    "  train_x,train_y,\n",
    "  batch_size = 32,\n",
    "  epochs = 10,\n",
    "  validation_split = .2\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 4:** Let us evaluate the model and print out its test scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test score: 1.067133 \n",
      "Test accuracy 0.75688"
     ]
    }
   ],
   "source": [
    "scores <- model %>% evaluate(\n",
    "  test_x, test_y,\n",
    "  batch_size = 32\n",
    ")\n",
    "\n",
    "cat('Test score:', scores[[1]],'\\n')\n",
    "cat('Test accuracy', scores[[2]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How it works..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1 we instantiated a keras sequential model.\n",
    "\n",
    "Step 2 We add layers to the the sequential model. Fist we add an embedding layer which reduces the dimensionality of the input feature space, next we add a simple rnn in a bidirectional wrapper with \"merge_mode\" equal to \"concat\".\n",
    "Merge mode defines how to combine outputs of the forward and backward RNNs, Other modes can be 'sum', 'mul',  'ave'or NULL.At last we add a dense layer with one hidden unit and sigmoid as the activation function.\n",
    "\n",
    "Step 3, We compile the model with \"binary_crossentropy\" as the loss function since we are solving a binary classification problem. The optimizer used is \"adam\". We then train our model on the training dataset.\n",
    "\n",
    "Step 4 We evaluate the test accuracy of our model to see how is our model performing on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequence generation with LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recurrent Neural Networks face difficulties in carrying information properly and long order dependencies between layers\n",
    "in large networks.\n",
    "Long Short Term Memory networks, generally referred to as “LSTMs” are an extension of RNNs which are capable of learning\n",
    "long-term dependencies and are widely used in deep learning to avoid vanishing gradient problem in RNNs.\n",
    "LSTMs combat vanishing gradients through a gating mechanism and are able to remove or add information to the cell state,\n",
    "carefully regulated by these gates which control the information to pass through.LSTMs have 3 kinds of gates, input, output and forget gate. The forget gate defines how much of the previous state ht-1 you want to allow to pass through. The input state defines how much of the newly computed state for the current input xt you want to let through, and the output gate defines how much of the internal state you want to expose to the next layer. \n",
    "\n",
    "\n",
    "In this recipe, we will implement LSTM for sequence prediction(many to one in this example).We will build a LSTM neural network which predicts occurrence of a word based on the previous sequence of words.This is also known as text generation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting ready..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example we will use \"Jack and Jill\" nursery rhyme as the source text to build a language model. It will take 2 words as input to predict next word. We start by importing the required libraries and reading our file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "library(keras)\n",
    "library(readr)\n",
    "library(stringr)\n",
    "data <- read_file(\"data/rhyme.txt\") %>% str_to_lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In NLP we refer our data as corpus. A corpus is a large collection of texts.Now let us look at the corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "'jack and jill went up the hill\\nto fetch a pail of water.\\njack fell down and broke his crown,\\nand jill came tumbling after.\\n\\nup jack got and home did trot\\nas fast as he could caper;\\nand went to bed to mend his head\\nwith vinegar and brown paper.\\n'"
      ],
      "text/latex": [
       "'jack and jill went up the hill\\textbackslash{}nto fetch a pail of water.\\textbackslash{}njack fell down and broke his crown,\\textbackslash{}nand jill came tumbling after.\\textbackslash{}n\\textbackslash{}nup jack got and home did trot\\textbackslash{}nas fast as he could caper;\\textbackslash{}nand went to bed to mend his head\\textbackslash{}nwith vinegar and brown paper.\\textbackslash{}n'"
      ],
      "text/markdown": [
       "'jack and jill went up the hill\\nto fetch a pail of water.\\njack fell down and broke his crown,\\nand jill came tumbling after.\\n\\nup jack got and home did trot\\nas fast as he could caper;\\nand went to bed to mend his head\\nwith vinegar and brown paper.\\n'"
      ],
      "text/plain": [
       "[1] \"jack and jill went up the hill\\nto fetch a pail of water.\\njack fell down and broke his crown,\\nand jill came tumbling after.\\n\\nup jack got and home did trot\\nas fast as he could caper;\\nand went to bed to mend his head\\nwith vinegar and brown paper.\\n\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to do it..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have imported corpus into the R environment. To build a language model, we need to convert it into a  sequence of integers. Let us define our tokenizer and fit it. We will use it later to convert text to an integer sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = text_tokenizer(num_words = 35,char_level = F)\n",
    "tokenizer %>% fit_text_tokenizer(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us look at number of unique words we have in our corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique words 37"
     ]
    }
   ],
   "source": [
    "cat(\"Number of unique words\", length(tokenizer$word_index))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$and</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>$jack</dt>\n",
       "\t\t<dd>2</dd>\n",
       "\t<dt>$to</dt>\n",
       "\t\t<dd>3</dd>\n",
       "\t<dt>$jill</dt>\n",
       "\t\t<dd>4</dd>\n",
       "\t<dt>$went</dt>\n",
       "\t\t<dd>5</dd>\n",
       "\t<dt>$up</dt>\n",
       "\t\t<dd>6</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$and] 1\n",
       "\\item[\\$jack] 2\n",
       "\\item[\\$to] 3\n",
       "\\item[\\$jill] 4\n",
       "\\item[\\$went] 5\n",
       "\\item[\\$up] 6\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$and\n",
       ":   1\n",
       "$jack\n",
       ":   2\n",
       "$to\n",
       ":   3\n",
       "$jill\n",
       ":   4\n",
       "$went\n",
       ":   5\n",
       "$up\n",
       ":   6\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$and\n",
       "[1] 1\n",
       "\n",
       "$jack\n",
       "[1] 2\n",
       "\n",
       "$to\n",
       "[1] 3\n",
       "\n",
       "$jill\n",
       "[1] 4\n",
       "\n",
       "$went\n",
       "[1] 5\n",
       "\n",
       "$up\n",
       "[1] 6\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(tokenizer$word_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us convert our corpus into a integer sequence using the tokenizer defined above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of 1\n",
      " $ : int [1:48] 2 1 4 5 6 9 10 3 11 12 ...\n"
     ]
    }
   ],
   "source": [
    "text_seqs <- texts_to_sequences(tokenizer, data)\n",
    "str(text_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that texts_to_sequences() returns a list. Let us convert it into a vector and print out its length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "48"
      ],
      "text/latex": [
       "48"
      ],
      "text/markdown": [
       "48"
      ],
      "text/plain": [
       "[1] 48"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "text_seqs <- text_seqs[[1]]\n",
    "length(text_seqs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "34"
      ],
      "text/latex": [
       "34"
      ],
      "text/markdown": [
       "34"
      ],
      "text/plain": [
       "[1] 34"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "max(text_seqs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us convert text sequence into an input(feature), and output(labels) sequences, where input will be a sequence of two consecutive words and output will be the next word that appears in the sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequence_length <- 2\n",
    "feature <- matrix(ncol = input_sequence_length)\n",
    "label <- matrix(ncol = 1)\n",
    "\n",
    "for(i in seq(input_sequence_length, length(text_seqs))){\n",
    "    if(i >= length(text_seqs)){\n",
    "        break()\n",
    "    }\n",
    "    start_idx <- (i - input_sequence_length) +1\n",
    "    end_idx <- i +1\n",
    "    new_seq <-  text_seqs[start_idx:end_idx]\n",
    "    feature <- rbind(feature,new_seq[1:input_sequence_length])\n",
    "    label <- rbind(label,new_seq[input_sequence_length+1])\n",
    "}\n",
    "feature <- feature[-1,]\n",
    "label <- label[-1,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "'Feature'"
      ],
      "text/latex": [
       "'Feature'"
      ],
      "text/markdown": [
       "'Feature'"
      ],
      "text/plain": [
       "[1] \"Feature\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>2 </td><td> 1</td></tr>\n",
       "\t<tr><td>1 </td><td> 4</td></tr>\n",
       "\t<tr><td>4 </td><td> 5</td></tr>\n",
       "\t<tr><td>5 </td><td> 6</td></tr>\n",
       "\t<tr><td>6 </td><td> 9</td></tr>\n",
       "\t<tr><td>9 </td><td>10</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       "\t 2  &  1\\\\\n",
       "\t 1  &  4\\\\\n",
       "\t 4  &  5\\\\\n",
       "\t 5  &  6\\\\\n",
       "\t 6  &  9\\\\\n",
       "\t 9  & 10\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 2  |  1 |\n",
       "| 1  |  4 |\n",
       "| 4  |  5 |\n",
       "| 5  |  6 |\n",
       "| 6  |  9 |\n",
       "| 9  | 10 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1] [,2]\n",
       "[1,] 2     1  \n",
       "[2,] 1     4  \n",
       "[3,] 4     5  \n",
       "[4,] 5     6  \n",
       "[5,] 6     9  \n",
       "[6,] 9    10  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "'label'"
      ],
      "text/latex": [
       "'label'"
      ],
      "text/markdown": [
       "'label'"
      ],
      "text/plain": [
       "[1] \"label\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>4</li>\n",
       "\t<li>5</li>\n",
       "\t<li>6</li>\n",
       "\t<li>9</li>\n",
       "\t<li>10</li>\n",
       "\t<li>3</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 4\n",
       "\\item 5\n",
       "\\item 6\n",
       "\\item 9\n",
       "\\item 10\n",
       "\\item 3\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 4\n",
       "2. 5\n",
       "3. 6\n",
       "4. 9\n",
       "5. 10\n",
       "6. 3\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1]  4  5  6  9 10  3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "paste(\"Feature\")\n",
    "head(feature)\n",
    "paste(\"label\")\n",
    "head(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's on-hot-encode our label and show the dimensions of our features and labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "label <- to_categorical(label,num_classes = tokenizer$num_words )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features 46 2 \n",
      "Shape of label 1610"
     ]
    }
   ],
   "source": [
    "cat(\"Shape of features\",dim(feature),\"\\n\")\n",
    "cat(\"Shape of label\",length(label))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 2:** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us create our neural network for text generation and print its summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model <- keras_model_sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Layer (type)                        Output Shape                    Param #     \n",
      "================================================================================\n",
      "embedding (Embedding)               (None, 2, 10)                   350         \n",
      "________________________________________________________________________________\n",
      "lstm (LSTM)                         (None, 50)                      12200       \n",
      "________________________________________________________________________________\n",
      "dense (Dense)                       (None, 35)                      1785        \n",
      "________________________________________________________________________________\n",
      "activation (Activation)             (None, 35)                      0           \n",
      "================================================================================\n",
      "Total params: 14,335\n",
      "Trainable params: 14,335\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model <- keras_model_sequential()\n",
    "model %>%\n",
    "    layer_embedding(input_dim = tokenizer$num_words,output_dim = 10,input_length = input_sequence_length) %>%\n",
    "    layer_lstm(units = 50) %>%\n",
    "    layer_dense(tokenizer$num_words) %>%\n",
    "    layer_activation(\"softmax\")\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we compile the model and train it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile\n",
    "model %>% compile(\n",
    "    loss = \"categorical_crossentropy\", \n",
    "    optimizer = optimizer_rmsprop(lr = 0.001),\n",
    "    metrics = c('accuracy')\n",
    ")\n",
    "\n",
    "# train\n",
    "model %>% fit(\n",
    "  feature, label,\n",
    "#   batch_size = 128,\n",
    "  epochs = 500\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 3:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following code block, we implement a function to generate a sequence from a language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_sequence <-function(model, tokenizer, input_length, seed_text, predict_next_n_words){\n",
    "    input_text <- seed_text\n",
    "    for(i in seq(predict_next_n_words)){\n",
    "        encoded <- texts_to_sequences(tokenizer,input_text)[[1]]\n",
    "        encoded <- pad_sequences(sequences = list(encoded),maxlen = input_length,padding = 'pre')\n",
    "        yhat <- predict_classes(model,encoded, verbose=0)\n",
    "        next_word <- tokenizer$index_word[[as.character(yhat)]]\n",
    "        input_text <- paste(input_text, next_word)\n",
    "    }\n",
    "    return(input_text)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use our previously written custom function, generate_sequence(), to generate text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text generated from seed 1:  Jack and jill went up the hill to fetch a pail of water \n",
      " Text generated from seed 2:  Jack fell down and broke his crown and jill went up the hill"
     ]
    }
   ],
   "source": [
    "seed_1 = \"Jack and\"\n",
    "cat(\"Text generated from seed 1: \" ,generate_sequence(model,tokenizer,input_sequence_length,seed_1,11),\"\\n \")\n",
    "seed_2 = \"Jack fell\"\n",
    "cat(\"Text generated from seed 2: \",generate_sequence(model,tokenizer,input_sequence_length,seed_2,11))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How it works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Step 1:\n",
    "To build any language model, we clean the input text and break it into tokens. Tokens are individual words and breaking text into its different words is called tokenization. The keras tokenizer by default splits the corpus into a list of tokens( \" \" is used for splitting sentences into words), it removes all punctuation, converts the words into lowercase, and builds an internal vocabulary based on the input text.\n",
    "\n",
    "Vocabulary generated by tokenizer is an indexed list where words are indexed by overall frequency in the dataset. We can see that in the nursery rhyme, \"and\" is the most frequent word and \"up\" ist the 5th most frequent word and it has 37 unique words.Next we convert our corpus into an integes sequence.Please note that \"num_words\" argument of text_tokenizer() defines the maximum number of words to keep, based on word frequency. It means that only top \"n\" frequent words are kept in the encoded sequence.Next, we prepare feature and lables from our corpus.\n",
    "\n",
    "Step 2:\n",
    "In this step we define our LSTM neuarl network. We first initialilize a sequential model an then add an embedding layer to it. Embedding layer transforms the input feature space into a latent feature with \"n\" dimension, in our exapmle it transforms it into 128 latent features. Next we add LSTM layer with 50 units. Word prediction is a classifiaction problen where we predict next one word from vocabulary,therefore we add a dense layer with units equal to the number of words in vocbulary with softmax activation function.\n",
    "\n",
    "Step 3:\n",
    "\n",
    "We define a function to generate text from a given initial set of two words. Our model predicts next word from the original 2 words, in our example, initial seed is \"Jack and\" and the predicted word is \"jill\" thus creating a three-word sequence. In the next iteration, we take the last two words of the sentence, i.e. \"and jill\" and predict next word, \"went\". The function continues to generate text until we have generated words equal to the value of the argument \"predict_next_n_words\".\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## There is more..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While working on NLP applications,we contruct meaningfull features from the text data. There are many techniques using which we can construct these features like count vectorzation,binary vectorization ,tf-idf(Term frequency-inverse document frequency), word embeddings etc. Following code block demonstrates how we can built a tf-df faeture matrix for various NLP applications using keras libraray in R."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>0        </td><td>1.131961 </td><td>0.8509141</td><td>0.8509141</td><td>0.6865121</td><td>0.6865121</td><td>0.6865121</td><td>0.6865121</td><td>0.6865121</td><td>0.4054651</td><td>⋯        </td><td>0.4054651</td><td>0.4054651</td><td>0.4054651</td><td>0.4054651</td><td>0.4054651</td><td>0.4054651</td><td>0.4054651</td><td>0.4054651</td><td>0.4054651</td><td>0.4054651</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{lllllllllllllllllllllllllllllllllll}\n",
       "\t 0         & 1.131961  & 0.8509141 & 0.8509141 & 0.6865121 & 0.6865121 & 0.6865121 & 0.6865121 & 0.6865121 & 0.4054651 & ⋯         & 0.4054651 & 0.4054651 & 0.4054651 & 0.4054651 & 0.4054651 & 0.4054651 & 0.4054651 & 0.4054651 & 0.4054651 & 0.4054651\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "| 0         | 1.131961  | 0.8509141 | 0.8509141 | 0.6865121 | 0.6865121 | 0.6865121 | 0.6865121 | 0.6865121 | 0.4054651 | ⋯         | 0.4054651 | 0.4054651 | 0.4054651 | 0.4054651 | 0.4054651 | 0.4054651 | 0.4054651 | 0.4054651 | 0.4054651 | 0.4054651 |\n",
       "\n"
      ],
      "text/plain": [
       "     [,1] [,2]     [,3]      [,4]      [,5]      [,6]      [,7]      [,8]     \n",
       "[1,] 0    1.131961 0.8509141 0.8509141 0.6865121 0.6865121 0.6865121 0.6865121\n",
       "     [,9]      [,10]     [,11] [,12]     [,13]     [,14]     [,15]    \n",
       "[1,] 0.6865121 0.4054651 ⋯     0.4054651 0.4054651 0.4054651 0.4054651\n",
       "     [,16]     [,17]     [,18]     [,19]     [,20]     [,21]    \n",
       "[1,] 0.4054651 0.4054651 0.4054651 0.4054651 0.4054651 0.4054651"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "texts_to_matrix(tokenizer, data, mode = c(\"tfidf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other modes available are - \"binary\",\"count\",\"freq\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

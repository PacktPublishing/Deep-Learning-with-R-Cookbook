{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# importing the required libraries\n",
    "library(magick)\n",
    "library(image.libfacedetection)\n",
    "library(keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading a sample input image and resizing it\n",
    "width_resized = 500\n",
    "height_resized = 500\n",
    "\n",
    "test_img = image_read(\"data/face_recognition/brad_pitt/brad_pitt_21.jpg\")\n",
    "test_img <- image_scale(test_img,paste0(width_resized,\"x\",height_resized,sep =\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# localizing the face in the image\n",
    "faces <- image_detect_faces(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>x</th><th scope=col>y</th><th scope=col>width</th><th scope=col>height</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>239</td><td>26 </td><td>52 </td><td>52 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " x & y & width & height\\\\\n",
       "\\hline\n",
       "\t 239 & 26  & 52  & 52 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "x | y | width | height | \n",
       "|---|\n",
       "| 239 | 26  | 52  | 52  | \n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  x   y  width height\n",
       "1 239 26 52    52    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# printing and saving the attributes of the face locale\n",
    "faces$detections[,1:4]\n",
    "face_width = faces$detections$width\n",
    "face_height = faces$detections$height \n",
    "face_x = faces$detections$x\n",
    "face_y = faces$detections$y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drawing a bounding box around the face\n",
    "test_img <- image_draw(test_img)\n",
    "rect(xleft = face_x,ybottom = face_y,xright = face_x+ face_width,ytop = face_y+ face_height,lwd = 2,border = \"red\")\n",
    "dev.off()\n",
    "plot(test_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preparing the training data by resizing, localizing and cropping each face in the data\n",
    "\n",
    "fold = list.dirs('data/face_recognition',full.names = FALSE, recursive = FALSE)\n",
    "fold = grep(paste0(\"face\", collapse = \"|\"), fold, invert = TRUE, value = TRUE)\n",
    "\n",
    "train_data_dir = \"data/face_recognition/faces/\"\n",
    "dir.create(train_data_dir)\n",
    "\n",
    "for (i in fold){\n",
    "    files = list.files(path = paste0(\"data/face_recognition/\",i),full.names = FALSE)\n",
    "    for (face_file in files){\n",
    "        img = image_read(paste0(\"data/face_recognition/\",i,\"/\",face_file,sep= \"\"))\n",
    "        img <- image_scale(img,paste0(width_resized,\"x\",height_resized,sep =\"\"))\n",
    "        faces <- image_detect_faces(img)\n",
    "        face_width = faces$detections$width\n",
    "        face_height = faces$detections$height\n",
    "        face_x = faces$detections$x\n",
    "        face_y = faces$detections$y\n",
    "        face_dim= paste0(face_width,\"x\",face_height,\"+\",face_x,\"+\",face_y)\n",
    "        face_cropped = image_crop(img,face_dim)\n",
    "        face_cropped = image_crop(img,face_dim)\n",
    "        if(nchar(face_dim)<= 3){\n",
    "            print(paste(\"empty face in:\",face_file))\n",
    "            print(face_file)\n",
    "        }else{\n",
    "            fold_name = paste0(train_data_dir,\"/\",i,\"_face\")\n",
    "            dir.create(fold_name)\n",
    "            image_write(face_cropped,paste0(fold_name,\"/\",face_file))\n",
    "                      \n",
    "        }\n",
    "        \n",
    "    }\n",
    "} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting the size of the training images\n",
    "train_path = \"data/face_recognition/faces/\"\n",
    "img_size = c(160,160)\n",
    "img_channels = 3\n",
    "\n",
    "class_label = list.dirs('data/face_recognition/faces', full.names = FALSE, recursive = TRUE)[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building a training generator\n",
    "train_data_generator <- image_data_generator(rotation_range = 10,shear_range = .2,rescale = 1/255,\n",
    "                                            width_shift_range = 0.1,\n",
    "                                            height_shift_range = 0.1,\n",
    "                                            fill_mode = \"nearest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# getting the data\n",
    "train_data <- flow_images_from_directory(directory = train_path,shuffle = T,\n",
    "                                         generator = train_data_generator,\n",
    "                                         target_size = img_size,\n",
    "                                         color_mode = \"rgb\",\n",
    "                                         class_mode = \"categorical\",\n",
    "                                         classes = class_label,\n",
    "                                         batch_size = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the FaceNet model\n",
    "facenet <- load_model_hdf5(\"facenet_keras.h5\")\n",
    "\n",
    "print(facenet$input)\n",
    "print(facenet$output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building our face recognition model\n",
    "facenet_out <- facenet$output %>%\n",
    "layer_dense(units = 128,activation = \"relu\") %>%\n",
    "layer_dense(units = 3,activation = \"softmax\")\n",
    "\n",
    "facenet_model <- keras_model(inputs = facenet$input, outputs = facenet_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freezing the pre-realised imagenet weights of the FaceNet the model\n",
    "freeze_weights(facenet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "facenet_model %>% compile(optimizer = 'rmsprop', loss = 'categorical_crossentropy',metrics = c('accuracy'))\n",
    "\n",
    "# training the model\n",
    "facenet_model %>% fit_generator(generator = train_data,steps_per_epoch = 2,\n",
    "                                 epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the model\n",
    "facenet_model %>% save_model_hdf5(paste0(\"facenet_model.h5\",sep=\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<strong>png:</strong> 2"
      ],
      "text/latex": [
       "\\textbf{png:} 2"
      ],
      "text/markdown": [
       "**png:** 2"
      ],
      "text/plain": [
       "png \n",
       "  2 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# recognizing face from a sample image and plotting it \n",
    "test_img = image_read(\"data/face_recognition/brad_pitt/brad_pitt_10.jpg\")\n",
    "test_img <- image_scale(test_img,paste0(width_resized,\"x\",height_resized,sep =\"\"))\n",
    "faces <- image_detect_faces(test_img)\n",
    "\n",
    "face_width = faces$detections$width\n",
    "face_height = faces$detections$height\n",
    "face_x = faces$detections$x\n",
    "face_y = faces$detections$y\n",
    "\n",
    "face_dim= paste0(face_width,\"x\",face_height,\"+\",face_x,\"+\",face_y)\n",
    "face_cropped = image_crop(test_img,face_dim)\n",
    "face_cropped = image_resize(image = face_cropped,paste0(img_size[1],\"x\",img_size[2]))\n",
    "face_cropped_arr <- as.integer(face_cropped[[1]])/255\n",
    "face_cropped_arr <- array_reshape(face_cropped_arr,dim = c(1,img_size,img_channels))\n",
    "pred <- facenet_model %>% predict(face_cropped_arr)\n",
    "pred_class <- class_label[which.max(pred)]\n",
    "\n",
    "test_img <- image_draw(test_img)\n",
    "rect(xleft = face_x,ybottom = face_y,xright = face_x+ face_width,ytop = face_y+ face_height,lwd = 2,border = \"red\")\n",
    "text(face_x,face_y,pred_class,offset = 1,pos = 2,cex = 1.5,col = \"pink\")\n",
    "dev.off()\n",
    "\n",
    "plot(test_img)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

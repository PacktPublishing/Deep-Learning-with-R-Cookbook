{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the required libraries\n",
    "library(keras)\n",
    "library(reticulate)\n",
    "library(abind)\n",
    "library(grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the data and resizing them on the fly\n",
    "\n",
    "train_path <- \"data/flowers/\"\n",
    "\n",
    "\n",
    "image_width = 32\n",
    "image_height = 32\n",
    "target_image_size = c(image_width,image_height)\n",
    "\n",
    "\n",
    "training_data <- flow_images_from_directory(directory = train_path,\n",
    "                                        target_size = target_image_size,\n",
    "                                        color_mode = \"rgb\",\n",
    "                                        class_mode = NULL,\n",
    "                                        batch_size = 2500)\n",
    "\n",
    "training_data = as_iterator(training_data)\n",
    "training_data = iter_next(training_data)\n",
    "training_data <- training_data/255\n",
    "dim(training_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining network parameters\n",
    "latent_dim <- 32\n",
    "height <- 32\n",
    "width <- 32\n",
    "channels <- 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating the generator network\n",
    "input_generator <- layer_input(shape = c(latent_dim))\n",
    "\n",
    "output_generator <- input_generator %>% \n",
    "  \n",
    "  # We transform the input data into a 16x16 128-channels feature map initially\n",
    "  layer_dense(units = 128 * 16 * 16) %>%\n",
    "  layer_activation_leaky_relu() %>% \n",
    "  layer_reshape(target_shape = c(16, 16, 128)) %>% \n",
    "  \n",
    "  # Next ,we add a convolution layer\n",
    "  layer_conv_2d(filters = 256, kernel_size = 5, \n",
    "                padding = \"same\") %>% \n",
    "  layer_activation_leaky_relu() %>% \n",
    "  \n",
    "  # Now we upsample the data \n",
    "  layer_conv_2d_transpose(filters = 256, kernel_size = 4, \n",
    "                          strides = 2, padding = \"same\") %>% \n",
    "  layer_activation_leaky_relu() %>%\n",
    "  \n",
    "  # Now we add more convolutional layers to the network\n",
    "  layer_conv_2d(filters = 256, kernel_size = 5, \n",
    "                padding = \"same\") %>% \n",
    "  layer_activation_leaky_relu() %>% \n",
    "  layer_conv_2d(filters = 256, kernel_size = 5, \n",
    "                padding = \"same\") %>% \n",
    "  layer_activation_leaky_relu() %>% \n",
    "  \n",
    "  # Produce a 32x32 1-channel feature map\n",
    "  layer_conv_2d(filters = channels, kernel_size = 7,\n",
    "                activation = \"tanh\", padding = \"same\")\n",
    "\n",
    "generator <- keras_model(input_generator, output_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Layer (type)                        Output Shape                    Param #     \n",
      "================================================================================\n",
      "input_1 (InputLayer)                (None, 32)                      0           \n",
      "________________________________________________________________________________\n",
      "dense (Dense)                       (None, 32768)                   1081344     \n",
      "________________________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)             (None, 32768)                   0           \n",
      "________________________________________________________________________________\n",
      "reshape (Reshape)                   (None, 16, 16, 128)             0           \n",
      "________________________________________________________________________________\n",
      "conv2d (Conv2D)                     (None, 16, 16, 256)             819456      \n",
      "________________________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)           (None, 16, 16, 256)             0           \n",
      "________________________________________________________________________________\n",
      "conv2d_transpose (Conv2DTranspose)  (None, 32, 32, 256)             1048832     \n",
      "________________________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)           (None, 32, 32, 256)             0           \n",
      "________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)                   (None, 32, 32, 256)             1638656     \n",
      "________________________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)           (None, 32, 32, 256)             0           \n",
      "________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)                   (None, 32, 32, 256)             1638656     \n",
      "________________________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)           (None, 32, 32, 256)             0           \n",
      "________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)                   (None, 32, 32, 3)               37635       \n",
      "================================================================================\n",
      "Total params: 6,264,579\n",
      "Trainable params: 6,264,579\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# summary of the generator network\n",
    "summary(generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "________________________________________________________________________________\n",
      "Layer (type)                        Output Shape                    Param #     \n",
      "================================================================================\n",
      "input_2 (InputLayer)                (None, 32, 32, 3)               0           \n",
      "________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)                   (None, 30, 30, 128)             3584        \n",
      "________________________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)           (None, 30, 30, 128)             0           \n",
      "________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)                   (None, 14, 14, 128)             262272      \n",
      "________________________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)           (None, 14, 14, 128)             0           \n",
      "________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)                   (None, 6, 6, 128)               262272      \n",
      "________________________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)           (None, 6, 6, 128)               0           \n",
      "________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)                   (None, 2, 2, 128)               262272      \n",
      "________________________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)           (None, 2, 2, 128)               0           \n",
      "________________________________________________________________________________\n",
      "flatten (Flatten)                   (None, 512)                     0           \n",
      "________________________________________________________________________________\n",
      "dropout (Dropout)                   (None, 512)                     0           \n",
      "________________________________________________________________________________\n",
      "dense_1 (Dense)                     (None, 1)                       513         \n",
      "================================================================================\n",
      "Total params: 790,913\n",
      "Trainable params: 790,913\n",
      "Non-trainable params: 0\n",
      "________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# creating the discriminator network\n",
    "\n",
    "input_discriminator <- layer_input(shape = c(height, width, channels))\n",
    "output_discriminator <- input_discriminator %>% \n",
    "  layer_conv_2d(filters = 128, kernel_size = 3) %>% \n",
    "  layer_activation_leaky_relu() %>% \n",
    "#   layer_dropout(0.25) %>%\n",
    "  layer_conv_2d(filters = 128, kernel_size = 4, strides = 2) %>% \n",
    "  layer_activation_leaky_relu() %>% \n",
    "#   layer_dropout(0.50) %>%\n",
    "  layer_conv_2d(filters = 128, kernel_size = 4, strides = 2) %>% \n",
    "  layer_activation_leaky_relu() %>% \n",
    "  layer_conv_2d(filters = 128, kernel_size = 4, strides = 2) %>% \n",
    "  layer_activation_leaky_relu() %>% \n",
    "  layer_flatten() %>%\n",
    "  # One dropout layer\n",
    "  layer_dropout(rate = 0.3) %>%  \n",
    "  # Classification layer\n",
    "  layer_dense(units = 1, activation = \"sigmoid\")\n",
    "discriminator <- keras_model(input_discriminator, output_discriminator)\n",
    "summary(discriminator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the discriminator network\n",
    "discriminator %>% compile(\n",
    "  optimizer = optimizer_rmsprop(lr = 0.0008,clipvalue = 1.0,decay = 1e-8),\n",
    "  loss = \"binary_crossentropy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freezing the weights of discriminator to make it non-trainable\n",
    "freeze_weights(discriminator) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# configuring the DCGAN network and compiling it\n",
    "gan_input <- layer_input(shape = c(latent_dim),name = 'dc_gan_input')\n",
    "gan_output <- discriminator(generator(gan_input))\n",
    "gan <- keras_model(gan_input, gan_output)\n",
    "\n",
    "gan %>% compile(\n",
    "  optimizer = optimizer_rmsprop(lr = 0.0004,clipvalue = 1.0,decay = 1e-8), \n",
    "  loss = \"binary_crossentropy\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# summary of the GAN model\n",
    "summary(gan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in dir.create(\"dcgan_images\"):\n",
      "“'dcgan_images' already exists”Warning message in dir.create(\"dcgan_model\"):\n",
      "“'dcgan_model' already exists”"
     ]
    }
   ],
   "source": [
    "# training our DCGAN network\n",
    "\n",
    "# defining network parameters\n",
    "iterations <- 2000\n",
    "batch_size <- 40\n",
    "dir.create(\"dcgan_images\")\n",
    "dir.create(\"dcgan_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the training\n",
    "start_index <- 1\n",
    "\n",
    "for (i in 1:iterations) {\n",
    "  \n",
    "  # Sample random points in the normally distributed latent space of dimension (batch_size * latent_dimension)\n",
    "  random_latent_vectors <- matrix(rnorm(batch_size * latent_dim), \n",
    "                                  nrow = batch_size, ncol = latent_dim)\n",
    "  \n",
    "  # Use generator network to decode the above random points to fake images\n",
    "  generated_images <- generator %>% predict(random_latent_vectors)\n",
    "  \n",
    "  # Combine the fake images with real images to build the training data for discriminator\n",
    "  stop_index <- start_index + batch_size - 1 \n",
    "  real_images <- training_data[start_index:stop_index,,,]\n",
    "  rows <- nrow(real_images)\n",
    "  combined_images <- array(0, dim = c(rows * 2, dim(real_images)[-1]))\n",
    "  combined_images[1:rows,,,] <- generated_images\n",
    "  combined_images[(rows+1):(rows*2),,,] <- real_images\n",
    " \n",
    "  # Prvide appropriate labels for real and fake images\n",
    "  labels <- rbind(matrix(1, nrow = batch_size, ncol = 1),\n",
    "                  matrix(0, nrow = batch_size, ncol = 1))\n",
    "  \n",
    "    # Adds random noise to the labels to increase robustness of the discriminator\n",
    "  labels <- labels + (0.5 * array(runif(prod(dim(labels))),\n",
    "                                  dim = dim(labels)))\n",
    "  \n",
    "    # Train the discriminator using both real and fake images\n",
    "  discriminator_loss <- discriminator %>% train_on_batch(combined_images, labels) \n",
    "  \n",
    "    # Sample random points in the latent space\n",
    "  random_latent_vectors <- matrix(rnorm(batch_size * latent_dim), \n",
    "                                  nrow = batch_size, ncol = latent_dim)\n",
    "  \n",
    "    # Assembles labels that say \"all real images\"\n",
    "  misleading_targets <- array(0, dim = c(batch_size, 1))\n",
    "  \n",
    "    # Train the generator by using the gan model,note that the discriminator weights are frozen\n",
    "  gan_model_loss <- gan %>% train_on_batch( \n",
    "    random_latent_vectors, \n",
    "    misleading_targets\n",
    "  )  \n",
    "  \n",
    "  start_index <- start_index + batch_size\n",
    "  if (start_index > (nrow(training_data) - batch_size))\n",
    "    start_index <- 1\n",
    "  \n",
    "  # At few iterations save the model and save generated images\n",
    "\n",
    "  if(i %in% c(5,10,15,20,40,100,200,500,800,1000,1500,2000)){\n",
    "\n",
    "        # Save model\n",
    "      save_model_hdf5(gan,paste0(\"dcgan_model/gan_model_\",i,\".h5\"))\n",
    "\n",
    "      # Save generated images\n",
    "      generated_images <- generated_images *255\n",
    "      generated_images  = array_reshape(generated_images ,dim = c(batch_size,32,32,3))\n",
    "      generated_images  = (generated_images -min(generated_images ))/(max(generated_images )-min(generated_images ))\n",
    "      grid = generated_images [1,,,]\n",
    "      for(j in seq(2,5)){\n",
    "          single = generated_images [j,,,]\n",
    "          grid = abind(grid,single,along = 2)\n",
    "      }\n",
    "      png(file=paste0(\"dcgan_images/generated_flowers_\",i,\".png\"),\n",
    "      width=600, height=350)\n",
    "      grid.raster(grid, interpolate=FALSE)\n",
    "      dev.off()  \n",
    "        \n",
    "  }\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
